{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:27.542940Z",
     "start_time": "2019-09-12T06:44:27.293516Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:28.463823Z",
     "start_time": "2019-09-12T06:44:28.021943Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:28.785015Z",
     "start_time": "2019-09-12T06:44:28.733131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\python\\recommender\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:30.909845Z",
     "start_time": "2019-09-12T06:44:29.333016Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import TorchMovielen10k, TorchTopcoder, DataBunch\n",
    "from models import FMLearner, TorchFM, TorchHrmFM, TorchPrmeFM, TorchTransFM\n",
    "from models.fm_learner import simple_loss, trans_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:31.839757Z",
     "start_time": "2019-09-12T06:44:31.533369Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = T.cuda.current_device()\n",
    "BATCH = 2000\n",
    "SHUFFLE = True\n",
    "WORKERS = 0\n",
    "REGS_PATH = Path(\"./inputs/topcoder/regs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:33.377181Z",
     "start_time": "2019-09-12T06:44:32.100595Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 14:44:32,538 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in inputs\\topcoder\\regs.csv\n",
      "2019-09-12 14:44:32,538 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in inputs\\topcoder\\regs.csv\n",
      "2019-09-12 14:44:32,538 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in inputs\\topcoder\\regs.csv\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0912 14:44:32.538454 14248 torch_topcoder.py:47] Read dataset in inputs\\topcoder\\regs.csv\n",
      "2019-09-12 14:44:32,545 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original regs shape: (610025, 3)\n",
      "2019-09-12 14:44:32,545 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original regs shape: (610025, 3)\n",
      "2019-09-12 14:44:32,545 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original regs shape: (610025, 3)\n",
      "I0912 14:44:32.545405 14248 torch_topcoder.py:48] Original regs shape: (610025, 3)\n",
      "2019-09-12 14:44:32,638 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original registants size: 60017\n",
      "2019-09-12 14:44:32,638 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original registants size: 60017\n",
      "2019-09-12 14:44:32,638 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original registants size: 60017\n",
      "I0912 14:44:32.638185 14248 torch_topcoder.py:53] Original registants size: 60017\n",
      "2019-09-12 14:44:32,644 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original challenges size: 39916\n",
      "2019-09-12 14:44:32,644 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original challenges size: 39916\n",
      "2019-09-12 14:44:32,644 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original challenges size: 39916\n",
      "I0912 14:44:32.644141 14248 torch_topcoder.py:54] Original challenges size: 39916\n",
      "2019-09-12 14:44:32,702 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter dataframe shape: (544568, 3)\n",
      "2019-09-12 14:44:32,702 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter dataframe shape: (544568, 3)\n",
      "2019-09-12 14:44:32,702 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter dataframe shape: (544568, 3)\n",
      "I0912 14:44:32.702017 14248 torch_topcoder.py:61] Filter dataframe shape: (544568, 3)\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_topcoder.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regs_df['previousId'][first_mask] = -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<datasets.torch_topcoder.TorchTopcoder at 0x21fa0e91eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topcoder_db = TorchTopcoder(REGS_PATH)\n",
    "topcoder_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:33.908482Z",
     "start_time": "2019-09-12T06:44:33.797722Z"
    }
   },
   "outputs": [],
   "source": [
    "topcoder_db.config_db(batch_size=BATCH,\n",
    "                      shuffle=SHUFFLE,\n",
    "                      num_workers=WORKERS,\n",
    "                      device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:34.595205Z",
     "start_time": "2019-09-12T06:44:34.484438Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_dim = topcoder_db.feat_dim\n",
    "NUM_DIM = 124\n",
    "INIT_MEAN = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:35.483994Z",
     "start_time": "2019-09-12T06:44:35.373197Z"
    }
   },
   "outputs": [],
   "source": [
    "# regst setting\n",
    "LINEAR_REG = 1\n",
    "EMB_REG = 1\n",
    "TRANS_REG = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:35.967007Z",
     "start_time": "2019-09-12T06:44:35.853339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function simple_loss at 0x0000021FA683D2F0>, 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_loss_callback = partial(simple_loss, LINEAR_REG, EMB_REG)\n",
    "simple_loss_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:37.990138Z",
     "start_time": "2019-09-12T06:44:37.877362Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "DECAY_FREQ = 1000\n",
    "DECAY_GAMMA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:38.591153Z",
     "start_time": "2019-09-12T06:44:38.285998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchFM()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_model = TorchFM(feature_dim=feat_dim, num_dim=NUM_DIM, init_mean=INIT_MEAN)\n",
    "fm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:40.124982Z",
     "start_time": "2019-09-12T06:44:40.013282Z"
    }
   },
   "outputs": [],
   "source": [
    "adam_opt = optim.Adam(fm_model.parameters(), lr=LEARNING_RATE)\n",
    "schedular = optim.lr_scheduler.StepLR(adam_opt, step_size=1000, gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:44:43.284046Z",
     "start_time": "2019-09-12T06:44:40.973734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.fm_learner.FMLearner at 0x21fb02c9d68>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_learner = FMLearner(fm_model, adam_opt, schedular, topcoder_db)\n",
    "fm_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T06:50:23.831159Z",
     "start_time": "2019-09-12T06:48:34.644961Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 0 step 0: training loss: 36595.257463009104\n",
      "Epoch 0 step 1: training loss: 35559.40638101382\n",
      "Epoch 0 step 2: training loss: 34565.72414944783\n",
      "Epoch 0 step 3: training loss: 33598.092547919754\n",
      "Epoch 0 step 4: training loss: 32690.78531390714\n",
      "Epoch 0 step 5: training loss: 31745.331099249604\n",
      "Epoch 0 step 6: training loss: 30880.821221724556\n",
      "Epoch 0 step 7: training loss: 30010.142860921136\n",
      "Epoch 0 step 8: training loss: 29126.861485908918\n",
      "Epoch 0 step 9: training loss: 28326.42653949232\n",
      "Epoch 0 step 10: training loss: 27514.757163635364\n",
      "Epoch 0 step 11: training loss: 26748.280416624504\n",
      "Epoch 0 step 12: training loss: 25935.456451214493\n",
      "Epoch 0 step 13: training loss: 25204.01370157827\n",
      "Epoch 0 step 14: training loss: 24507.248573880766\n",
      "Epoch 0 step 15: training loss: 23782.009283290605\n",
      "Epoch 0 step 16: training loss: 23076.729034108594\n",
      "Epoch 0 step 17: training loss: 22448.71968973585\n",
      "Epoch 0 step 18: training loss: 21751.941589665737\n",
      "Epoch 0 step 19: training loss: 21151.935140265832\n",
      "Epoch 0 step 20: training loss: 20521.807152183235\n",
      "Epoch 0 step 21: training loss: 19924.322203801283\n",
      "Epoch 0 step 22: training loss: 19303.225677076734\n",
      "Epoch 0 step 23: training loss: 18728.338395038056\n",
      "Epoch 0 step 24: training loss: 18188.0174728941\n",
      "Epoch 0 step 25: training loss: 17646.96348212716\n",
      "Epoch 0 step 26: training loss: 17106.16194258096\n",
      "Epoch 0 step 27: training loss: 16607.445781891834\n",
      "Epoch 0 step 28: training loss: 16104.541337117122\n",
      "Epoch 0 step 29: training loss: 15632.05017903092\n",
      "Epoch 0 step 30: training loss: 15143.811645000678\n",
      "Epoch 0 step 31: training loss: 14696.603443044305\n",
      "Epoch 0 step 32: training loss: 14260.630939316372\n",
      "Epoch 0 step 33: training loss: 13797.258192003887\n",
      "Epoch 0 step 34: training loss: 13391.19687513639\n",
      "Epoch 0 step 35: training loss: 12944.229603498421\n",
      "Epoch 0 step 36: training loss: 12583.15403367698\n",
      "Epoch 0 step 37: training loss: 12165.639502228676\n",
      "Epoch 0 step 38: training loss: 11808.91136583335\n",
      "Epoch 0 step 39: training loss: 11432.37921667233\n",
      "Epoch 0 step 40: training loss: 11086.425223285489\n",
      "Epoch 0 step 41: training loss: 10703.339682317303\n",
      "Epoch 0 step 42: training loss: 10396.625165241161\n",
      "Epoch 0 step 43: training loss: 10085.739527518504\n",
      "Epoch 0 step 44: training loss: 9772.32765490095\n",
      "Epoch 0 step 45: training loss: 9464.710966837427\n",
      "Epoch 0 step 46: training loss: 9141.906799049055\n",
      "Epoch 0 step 47: training loss: 8874.938992849417\n",
      "Epoch 0 step 48: training loss: 8586.521620059104\n",
      "Epoch 0 step 49: training loss: 8295.090422672634\n",
      "Epoch 0 step 50: training loss: 8036.73584293081\n",
      "Epoch 0 step 51: training loss: 7791.95711650459\n",
      "Epoch 0 step 52: training loss: 7556.249480409746\n",
      "Epoch 0 step 53: training loss: 7284.742591070834\n",
      "Epoch 0 step 54: training loss: 7070.712021673328\n",
      "Epoch 0 step 55: training loss: 6818.115574889367\n",
      "Epoch 0 step 56: training loss: 6626.717589172008\n",
      "Epoch 0 step 57: training loss: 6415.166263025933\n",
      "Epoch 0 step 58: training loss: 6196.7917152789905\n",
      "Epoch 0 step 59: training loss: 6002.775817107967\n",
      "Epoch 0 step 60: training loss: 5789.425206903369\n",
      "Epoch 0 step 61: training loss: 5622.064687651861\n",
      "Epoch 0 step 62: training loss: 5441.9742972878785\n",
      "Epoch 0 step 63: training loss: 5250.584143522521\n",
      "Epoch 0 step 64: training loss: 5098.512521679746\n",
      "Epoch 0 step 65: training loss: 4923.382561378644\n",
      "Epoch 0 step 66: training loss: 4760.486871244162\n",
      "Epoch 0 step 67: training loss: 4596.938790499192\n",
      "Epoch 0 step 68: training loss: 4462.417380454113\n",
      "Epoch 0 step 69: training loss: 4310.018551094602\n",
      "Epoch 0 step 70: training loss: 4165.439671511082\n",
      "Epoch 0 step 71: training loss: 4041.2044293962635\n",
      "Epoch 0 step 72: training loss: 3903.914459584131\n",
      "Epoch 0 step 73: training loss: 3774.1269631448536\n",
      "Epoch 0 step 74: training loss: 3640.2149208762585\n",
      "Epoch 0 step 75: training loss: 3544.5864121740888\n",
      "Epoch 0 step 76: training loss: 3415.9063490475446\n",
      "Epoch 0 step 77: training loss: 3324.478663697209\n",
      "Epoch 0 step 78: training loss: 3210.9103010935673\n",
      "Epoch 0 step 79: training loss: 3106.323335112833\n",
      "Epoch 0 step 80: training loss: 3024.2442718116527\n",
      "Epoch 0 step 81: training loss: 2890.775722387233\n",
      "Epoch 0 step 82: training loss: 2809.8899668657236\n",
      "Epoch 0 step 83: training loss: 2737.2813889047547\n",
      "Epoch 0 step 84: training loss: 2644.963133674926\n",
      "Epoch 0 step 85: training loss: 2564.2802281780496\n",
      "Epoch 0 step 86: training loss: 2466.3684904651745\n",
      "Epoch 0 step 87: training loss: 2375.947195845846\n",
      "Epoch 0 step 88: training loss: 2315.677565525834\n",
      "Epoch 0 step 89: training loss: 2247.499139387151\n",
      "Epoch 0 step 90: training loss: 2160.3146014848335\n",
      "Epoch 0 step 91: training loss: 2100.0725760744685\n",
      "Epoch 0 step 92: training loss: 2026.416155353981\n",
      "Epoch 0 step 93: training loss: 1980.0159515768473\n",
      "Epoch 0 step 94: training loss: 1910.7313800750253\n",
      "Epoch 0 step 95: training loss: 1845.2884074076826\n",
      "Epoch 0 step 96: training loss: 1800.6659534160917\n",
      "Epoch 0 step 97: training loss: 1748.866707244862\n",
      "Epoch 0 step 98: training loss: 1708.9078102872359\n",
      "Epoch 0 step 99: training loss: 1641.889930268988\n",
      "Epoch 0 step 100: training loss: 1597.712794020481\n",
      "Epoch 0 step 101: training loss: 1562.1757856021143\n",
      "Epoch 0 step 102: training loss: 1518.922098739596\n",
      "Epoch 0 step 103: training loss: 1451.4611644946556\n",
      "Epoch 0 step 104: training loss: 1416.184996071976\n",
      "Epoch 0 step 105: training loss: 1367.5845480815542\n",
      "Epoch 0 step 106: training loss: 1324.8081415825015\n",
      "Epoch 0 step 107: training loss: 1291.346408806353\n",
      "Epoch 0 step 108: training loss: 1262.1038119501393\n",
      "Epoch 0 step 109: training loss: 1220.2534531871365\n",
      "Epoch 0 step 110: training loss: 1192.3228967936643\n",
      "Epoch 0 step 111: training loss: 1162.8313615180934\n",
      "Epoch 0 step 112: training loss: 1132.5818262309629\n",
      "Epoch 0 step 113: training loss: 1100.3677669230929\n",
      "Epoch 0 step 114: training loss: 1074.8613577701506\n",
      "Epoch 0 step 115: training loss: 1037.0897827230283\n",
      "Epoch 0 step 116: training loss: 1009.4315427678748\n",
      "Epoch 0 step 117: training loss: 991.3825988412003\n",
      "Epoch 0 step 118: training loss: 958.1184265452614\n",
      "Epoch 0 step 119: training loss: 952.0237177646375\n",
      "Epoch 0 step 120: training loss: 914.7292510007182\n",
      "Epoch 0 step 121: training loss: 909.2223326715255\n",
      "Epoch 0 step 122: training loss: 884.8838401642333\n",
      "Epoch 0 step 123: training loss: 860.0968627629927\n",
      "Epoch 0 step 124: training loss: 845.1641748036942\n",
      "Epoch 0 step 125: training loss: 827.9089940982308\n",
      "Epoch 0 step 126: training loss: 804.429791925724\n",
      "Epoch 0 step 127: training loss: 779.4726867512777\n",
      "Epoch 0 step 128: training loss: 762.4610280301549\n",
      "Epoch 0 step 129: training loss: 757.8063348550365\n",
      "Epoch 0 step 130: training loss: 727.7522490453233\n",
      "Epoch 0 step 131: training loss: 709.7230173468391\n",
      "Epoch 0 step 132: training loss: 704.8836303815226\n",
      "Epoch 0 step 133: training loss: 687.7605140056138\n",
      "Epoch 0 step 134: training loss: 669.005174522729\n",
      "Epoch 0 step 135: training loss: 662.4964463438454\n",
      "Epoch 0 step 136: training loss: 669.5336039634554\n",
      "Epoch 0 step 137: training loss: 631.7518637191304\n",
      "Epoch 0 step 138: training loss: 625.6892005310015\n",
      "Epoch 0 step 139: training loss: 626.7289609061598\n",
      "Epoch 0 step 140: training loss: 605.9676247686068\n",
      "Epoch 0 step 141: training loss: 584.8991881209668\n",
      "Epoch 0 step 142: training loss: 597.9375646438878\n",
      "Epoch 0 step 143: training loss: 575.8122946866985\n",
      "Epoch 0 step 144: training loss: 568.1217448014501\n",
      "Epoch 0 step 145: training loss: 563.680967230779\n",
      "Epoch 0 step 146: training loss: 557.3949052415638\n",
      "Epoch 0 step 147: training loss: 545.7488734825084\n",
      "Epoch 0 step 148: training loss: 526.9962814156536\n",
      "Epoch 0 step 149: training loss: 526.9628581534181\n",
      "Epoch 0 step 150: training loss: 519.5235130293356\n",
      "Epoch 0 step 151: training loss: 509.38911149746923\n",
      "Epoch 0 step 152: training loss: 509.12803124801667\n",
      "Epoch 0 step 153: training loss: 490.41289547305144\n",
      "Epoch 0 step 154: training loss: 486.1536084877248\n",
      "Epoch 0 step 155: training loss: 494.9245233950378\n",
      "Epoch 0 step 156: training loss: 473.8768285397888\n",
      "Epoch 0 step 157: training loss: 488.84361989748214\n",
      "Epoch 0 step 158: training loss: 482.977502596346\n",
      "Epoch 0 step 159: training loss: 454.8922324690418\n",
      "Epoch 0 step 160: training loss: 466.79564639740704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 step 161: training loss: 471.59817159168153\n",
      "Epoch 0 step 162: training loss: 454.55296137684695\n",
      "Epoch 0 step 163: training loss: 441.30340475992307\n",
      "Epoch 0 step 164: training loss: 459.97532873326094\n",
      "Epoch 0 step 165: training loss: 425.96280588887595\n",
      "Epoch 0 step 166: training loss: 450.1372598482842\n",
      "Epoch 0 step 167: training loss: 438.6853764057085\n",
      "Epoch 0 step 168: training loss: 439.2942222913774\n",
      "Epoch 0 step 169: training loss: 420.39482700813556\n",
      "Epoch 0 step 170: training loss: 422.9234605200323\n",
      "Epoch 0 step 171: training loss: 415.51394037446073\n",
      "Epoch 0 step 172: training loss: 429.7578772458437\n",
      "Epoch 0 step 173: training loss: 428.0315576071465\n",
      "Epoch 0 step 174: training loss: 415.13823235984836\n",
      "Epoch 0 step 175: training loss: 400.3667745897594\n",
      "Epoch 0 step 176: training loss: 402.7374074812492\n",
      "Epoch 0 step 177: training loss: 391.6504437480455\n",
      "Epoch 0 step 178: training loss: 395.3935424855055\n",
      "Epoch 0 step 179: training loss: 400.18345007642887\n",
      "Epoch 0 step 180: training loss: 402.69653449702275\n",
      "Epoch 0 step 181: training loss: 401.2995639837438\n",
      "Epoch 0 step 182: training loss: 396.67668015485935\n",
      "Epoch 0 step 183: training loss: 386.84833352572844\n",
      "Epoch 0 step 184: training loss: 380.0282978183151\n",
      "Epoch 0 step 185: training loss: 369.5998734689814\n",
      "Epoch 0 step 186: training loss: 381.949798217891\n",
      "Epoch 0 step 187: training loss: 383.4603121681438\n",
      "Epoch 0 step 188: training loss: 385.2354023812145\n",
      "Epoch 0 step 189: training loss: 376.6359831217799\n",
      "Epoch 0 step 190: training loss: 373.74333307269177\n",
      "Epoch 0 step 191: training loss: 380.5700003687702\n",
      "Epoch 0 step 192: training loss: 369.8562310958183\n",
      "Epoch 0 step 193: training loss: 367.8999903625205\n",
      "Epoch 0 step 194: training loss: 382.7232061018426\n",
      "Epoch 0 step 195: training loss: 370.56955445966685\n",
      "Epoch 0 step 196: training loss: 368.29266598020513\n",
      "Epoch 0 step 197: training loss: 364.61272922413855\n",
      "Epoch 0 step 198: training loss: 376.464946902792\n",
      "Epoch 0 step 199: training loss: 362.3837692642961\n",
      "Epoch 0 step 200: training loss: 357.21663800936585\n",
      "Epoch 0 step 201: training loss: 350.90680302275655\n",
      "Epoch 0 step 202: training loss: 357.9509072019421\n",
      "Epoch 0 step 203: training loss: 356.3068715383987\n",
      "Epoch 0 step 204: training loss: 355.733068449469\n",
      "Epoch 0 step 205: training loss: 342.1437441043766\n",
      "Epoch 0 step 206: training loss: 352.26089497058\n",
      "Epoch 0 step 207: training loss: 369.3159300916139\n",
      "Epoch 0 step 208: training loss: 355.27804282063767\n",
      "Epoch 0 step 209: training loss: 349.59598321691016\n",
      "Epoch 0 step 210: training loss: 348.64739209729527\n",
      "Epoch 0 step 211: training loss: 346.1039988817439\n",
      "Epoch 0 step 212: training loss: 343.7726298803025\n",
      "Epoch 0 step 213: training loss: 351.6594417309276\n",
      "Epoch 0 step 214: training loss: 343.6713362570215\n",
      "Epoch 0 step 215: training loss: 352.8152111814757\n",
      "Epoch 0 step 216: training loss: 343.78610838480074\n",
      "Epoch 0 step 217: training loss: 353.942212233477\n",
      "Epoch 0 step 218: training loss: 344.43643683158444\n",
      "Epoch 0 step 219: training loss: 348.54377435629283\n",
      "Epoch 0 step 220: training loss: 337.8591691466408\n",
      "Epoch 0 step 221: training loss: 354.71720360607134\n",
      "Epoch 0 step 222: training loss: 342.159744453868\n",
      "Epoch 0 step 223: training loss: 335.5645085213142\n",
      "Epoch 0 step 224: training loss: 356.2723754033001\n",
      "Epoch 0 step 225: training loss: 361.1027015059069\n",
      "Epoch 0 step 226: training loss: 345.9547727827527\n",
      "Epoch 0 step 227: training loss: 342.85193033240654\n",
      "Epoch 0 step 228: training loss: 338.731452970364\n",
      "Epoch 0 step 229: training loss: 343.5695222182868\n",
      "Epoch 0 step 230: training loss: 349.02825704634336\n",
      "Epoch 0 step 231: training loss: 337.5940138096346\n",
      "Epoch 0 step 232: training loss: 345.896797140125\n",
      "Epoch 0 step 233: training loss: 340.3364346901439\n",
      "Epoch 0 step 234: training loss: 348.29946429245695\n",
      "Epoch 0 step 235: training loss: 344.5320346800295\n",
      "Epoch 0 step 236: training loss: 330.90709405962525\n",
      "Epoch 0 step 237: training loss: 324.7334713245633\n",
      "Epoch 0 step 238: training loss: 346.77275291225817\n",
      "Epoch 0 step 239: training loss: 339.20186660077854\n",
      "Epoch 0 step 240: training loss: 334.7061902001086\n",
      "Epoch 0 step 241: training loss: 331.18744979517203\n",
      "Epoch 0 step 242: training loss: 344.91464419878014\n",
      "Epoch 0 step 243: training loss: 330.7421057027509\n",
      "Epoch 0 step 244: training loss: 329.0701929260907\n",
      "Epoch 0 step 245: training loss: 332.6183094598023\n",
      "Epoch 0 step 246: training loss: 330.53612873565066\n",
      "Epoch 0 step 247: training loss: 337.30162072500235\n",
      "Epoch 0 step 248: training loss: 325.2957513735605\n",
      "Epoch 0 step 249: training loss: 330.01549941165155\n",
      "Epoch 0 step 250: training loss: 331.9327909645627\n",
      "Epoch 0 step 251: training loss: 333.9966817891474\n",
      "Epoch 0 step 252: training loss: 325.9827416095422\n",
      "Epoch 0 step 253: training loss: 330.0343173314722\n",
      "Epoch 0 step 254: training loss: 335.6448452339771\n",
      "Epoch 0 step 255: training loss: 334.6092515958819\n",
      "Epoch 0 step 256: training loss: 322.41068536134946\n",
      "Epoch 0 step 257: training loss: 312.62281956117545\n",
      "Epoch 0 step 258: training loss: 338.145629799388\n",
      "Epoch 0 step 259: training loss: 331.233367419983\n",
      "Epoch 0 step 260: training loss: 341.012337589004\n",
      "Epoch 0 step 261: training loss: 336.847249087319\n",
      "Epoch 0 step 262: training loss: 241.57380072100113\n",
      "Epoch 0: train loss 4800.87637115918, train accuarcy 0.7968395948410034\n",
      "Epoch 0: valid loss 1082.475247442931, valid accuarcy 0.9549221992492676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:49<00:00, 109.06s/it]\n"
     ]
    }
   ],
   "source": [
    "fm_learner.fit(epoch=1, loss_callback=simple_loss_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
