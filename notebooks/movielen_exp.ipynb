{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:13:22.449662Z",
     "start_time": "2019-09-12T05:13:22.161306Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:38:30.427304Z",
     "start_time": "2019-09-12T05:38:29.875690Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:38:30.988571Z",
     "start_time": "2019-09-12T05:38:30.979583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\python\\recommender\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:38:33.210675Z",
     "start_time": "2019-09-12T05:38:31.652030Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import TorchMovielen10k, TorchTopcoder, DataBunch\n",
    "from models import FMLearner, TorchFM, TorchHrmFM, TorchPrmeFM, TorchTransFM\n",
    "from models.fm_learner import simple_loss, trans_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:38:34.774656Z",
     "start_time": "2019-09-12T05:38:34.563160Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = T.cuda.current_device()\n",
    "BATCH = 1200\n",
    "SHUFFLE = True\n",
    "WORKERS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:38:35.814288Z",
     "start_time": "2019-09-12T05:38:35.540024Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-12 13:38:35,579 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-09-12 13:38:35,579 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-09-12 13:38:35,579 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0912 13:38:35.579915  4672 torch_movielen.py:58] Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-09-12 13:38:35,593 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "2019-09-12 13:38:35,593 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "2019-09-12 13:38:35,593 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "I0912 13:38:35.593879  4672 torch_movielen.py:62] Original user size: 943\n",
      "2019-09-12 13:38:35,600 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "2019-09-12 13:38:35,600 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "2019-09-12 13:38:35,600 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "I0912 13:38:35.600860  4672 torch_movielen.py:63] Original item size: 1682\n",
      "2019-09-12 13:38:35,610 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "2019-09-12 13:38:35,610 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "2019-09-12 13:38:35,610 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "I0912 13:38:35.610835  4672 torch_movielen.py:69] Filter user size: 943\n",
      "2019-09-12 13:38:35,617 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "2019-09-12 13:38:35,617 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "2019-09-12 13:38:35,617 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "I0912 13:38:35.617815  4672 torch_movielen.py:70] Filter item size: 1413\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:8682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_movielen.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._read_data_csv(data_path, user_min, item_min)\n"
     ]
    }
   ],
   "source": [
    "movie_db = TorchMovielen10k(data_path=\"./inputs/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:38:38.670954Z",
     "start_time": "2019-09-12T05:38:38.667962Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_db.config_db(batch_size=BATCH,\n",
    "                   shuffle=SHUFFLE,\n",
    "                   num_workers=WORKERS,\n",
    "                   device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:39:07.792376Z",
     "start_time": "2019-09-12T05:39:07.788387Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_dim = movie_db.feat_dim\n",
    "NUM_DIM = 124\n",
    "INIT_MEAN = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:39:09.822942Z",
     "start_time": "2019-09-12T05:39:09.819947Z"
    }
   },
   "outputs": [],
   "source": [
    "# regst setting\n",
    "LINEAR_REG = 1\n",
    "EMB_REG = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:39:10.500479Z",
     "start_time": "2019-09-12T05:39:10.492473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function simple_loss at 0x000001DC8321EBF8>, 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_loss_callback = partial(simple_loss, LINEAR_REG, EMB_REG)\n",
    "simple_loss_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train fm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:39:12.686505Z",
     "start_time": "2019-09-12T05:39:12.683513Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "DECAY_FREQ = 1000\n",
    "DECAY_GAMMA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_model = TorchFM(feature_dim=feat_dim, num_dim=NUM_DIM, init_mean=INIT_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:15:05.157600Z",
     "start_time": "2019-09-12T05:15:05.034830Z"
    }
   },
   "outputs": [],
   "source": [
    "adam_opt = optim.Adam(fm_model.parameters(), lr=LEARNING_RATE)\n",
    "schedular = optim.lr_scheduler.StepLR(adam_opt, step_size=1000, gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:15:13.635091Z",
     "start_time": "2019-09-12T05:15:11.122931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.fm_learner.FMLearner at 0x261880286d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_learner = FMLearner(fm_model, adam_opt, schedular, movie_db)\n",
    "fm_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:15:34.694413Z",
     "start_time": "2019-09-12T05:15:13.637056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 0 step 0: training loss: 2501.8791615108635\n",
      "Epoch 0 step 1: training loss: 2439.151191091701\n",
      "Epoch 0 step 2: training loss: 2353.3208519158243\n",
      "Epoch 0 step 3: training loss: 2305.3360514918677\n",
      "Epoch 0 step 4: training loss: 2245.827203822514\n",
      "Epoch 0 step 5: training loss: 2181.2016599677145\n",
      "Epoch 0 step 6: training loss: 2107.8690484889594\n",
      "Epoch 0 step 7: training loss: 2060.6322672918714\n",
      "Epoch 0 step 8: training loss: 2031.7019787327426\n",
      "Epoch 0 step 9: training loss: 1968.1715763727727\n",
      "Epoch 0 step 10: training loss: 1951.2065629142382\n",
      "Epoch 0 step 11: training loss: 1918.6806564026247\n",
      "Epoch 0 step 12: training loss: 1859.6477156169585\n",
      "Epoch 0 step 13: training loss: 1838.5822166555104\n",
      "Epoch 0 step 14: training loss: 1782.112176868077\n",
      "Epoch 0 step 15: training loss: 1761.410802360032\n",
      "Epoch 0 step 16: training loss: 1752.4130138905662\n",
      "Epoch 0 step 17: training loss: 1706.576410142721\n",
      "Epoch 0 step 18: training loss: 1675.1544457057553\n",
      "Epoch 0 step 19: training loss: 1646.7690095903206\n",
      "Epoch 0 step 20: training loss: 1607.7006446931548\n",
      "Epoch 0 step 21: training loss: 1601.1678385429868\n",
      "Epoch 0 step 22: training loss: 1565.7964444188885\n",
      "Epoch 0 step 23: training loss: 1529.074195036024\n",
      "Epoch 0 step 24: training loss: 1506.444085934284\n",
      "Epoch 0 step 25: training loss: 1498.3424310149817\n",
      "Epoch 0 step 26: training loss: 1466.3119140734789\n",
      "Epoch 0 step 27: training loss: 1438.9140593950788\n",
      "Epoch 0 step 28: training loss: 1426.5513878447096\n",
      "Epoch 0 step 29: training loss: 1386.6598984871132\n",
      "Epoch 0 step 30: training loss: 1385.9162469914622\n",
      "Epoch 0 step 31: training loss: 1369.031105807878\n",
      "Epoch 0 step 32: training loss: 1344.1125475936303\n",
      "Epoch 0 step 33: training loss: 1319.5253720208786\n",
      "Epoch 0 step 34: training loss: 1329.970002935282\n",
      "Epoch 0 step 35: training loss: 1288.4376099371616\n",
      "Epoch 0 step 36: training loss: 1273.4247619663774\n",
      "Epoch 0 step 37: training loss: 1261.9266984687283\n",
      "Epoch 0 step 38: training loss: 1257.6370622890172\n",
      "Epoch 0 step 39: training loss: 1226.4293615198471\n",
      "Epoch 0 step 40: training loss: 1208.3282557827401\n",
      "Epoch 0 step 41: training loss: 1183.4626335006399\n",
      "Epoch 0 step 42: training loss: 1192.4403173925366\n",
      "Epoch 0 step 43: training loss: 1159.398333503807\n",
      "Epoch 0 step 44: training loss: 1149.5483639442145\n",
      "Epoch 0 step 45: training loss: 1117.0934597580824\n",
      "Epoch 0 step 46: training loss: 1120.7250064527325\n",
      "Epoch 0 step 47: training loss: 1103.1416976839362\n",
      "Epoch 0 step 48: training loss: 1083.101553723569\n",
      "Epoch 0 step 49: training loss: 1080.9993682196068\n",
      "Epoch 0 step 50: training loss: 1032.8005771583244\n",
      "Epoch 0 step 51: training loss: 1054.1259993837875\n",
      "Epoch 0 step 52: training loss: 1052.1859476621048\n",
      "Epoch 0 step 53: training loss: 1027.4725048585983\n",
      "Epoch 0 step 54: training loss: 1017.3838923138968\n",
      "Epoch 0 step 55: training loss: 1008.9352825009807\n",
      "Epoch 0 step 56: training loss: 986.2720830758086\n",
      "Epoch 0 step 57: training loss: 971.1200023394011\n",
      "Epoch 0 step 58: training loss: 953.6151552599758\n",
      "Epoch 0 step 59: training loss: 947.3317940496946\n",
      "Epoch 0 step 60: training loss: 946.5664945848084\n",
      "Epoch 0 step 61: training loss: 924.7389441952761\n",
      "Epoch 0 step 62: training loss: 929.4124780875277\n",
      "Epoch 0 step 63: training loss: 903.5143905573643\n",
      "Epoch 0 step 64: training loss: 898.9997443951264\n",
      "Epoch 0 step 65: training loss: 888.6790205186338\n",
      "Epoch 0 step 66: training loss: 882.8463692477897\n",
      "Epoch 0 step 67: training loss: 849.3723622301167\n",
      "Epoch 0 step 68: training loss: 852.8539481602951\n",
      "Epoch 0 step 69: training loss: 835.6376743662629\n",
      "Epoch 0 step 70: training loss: 821.3393980036553\n",
      "Epoch 0 step 71: training loss: 805.1712751387627\n",
      "Epoch 0 step 72: training loss: 821.5028339225782\n",
      "Epoch 0 step 73: training loss: 801.5021172851826\n",
      "Epoch 0 step 74: training loss: 797.3405001483927\n",
      "Epoch 0 step 75: training loss: 809.7119315782192\n",
      "Epoch 0 step 76: training loss: 778.3731553966944\n",
      "Epoch 0 step 77: training loss: 757.2576769166204\n",
      "Epoch 0 step 78: training loss: 742.799965390082\n",
      "Epoch 0 step 79: training loss: 734.6109088655498\n",
      "Epoch 0 step 80: training loss: 723.6639098790782\n",
      "Epoch 0 step 81: training loss: 602.1298623047172\n",
      "Epoch 0: train loss 1313.7624982870948, train accuarcy 0.770267128944397\n",
      "Epoch 0: valid loss 720.0932550591465, valid accuarcy 0.8748674392700195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.93s/it]\n"
     ]
    }
   ],
   "source": [
    "fm_learner.fit(epoch=1, loss_callback=simple_loss_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train HRM FM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:18:42.658460Z",
     "start_time": "2019-09-12T05:18:42.523821Z"
    }
   },
   "outputs": [],
   "source": [
    "hrm_model = TorchHrmFM(feature_dim=feat_dim, num_dim=NUM_DIM, init_mean=INIT_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:18:54.173128Z",
     "start_time": "2019-09-12T05:18:54.035930Z"
    }
   },
   "outputs": [],
   "source": [
    "adam_opt = optim.Adam(hrm_model.parameters(), lr=LEARNING_RATE)\n",
    "schedular = optim.lr_scheduler.StepLR(adam_opt,\n",
    "                                      step_size=1000,\n",
    "                                      gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:19:31.692796Z",
     "start_time": "2019-09-12T05:19:31.557246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.fm_learner.FMLearner at 0x2618ef45710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrm_learner = FMLearner(hrm_model, adam_opt, schedular, movie_db)\n",
    "hrm_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:30:42.946336Z",
     "start_time": "2019-09-12T05:30:22.604849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 0 step 0: training loss: 2406.773105461969\n",
      "Epoch 0 step 1: training loss: 2362.5704801540946\n",
      "Epoch 0 step 2: training loss: 2326.1173888264775\n",
      "Epoch 0 step 3: training loss: 2282.1781139256946\n",
      "Epoch 0 step 4: training loss: 2242.908122727894\n",
      "Epoch 0 step 5: training loss: 2206.786883228701\n",
      "Epoch 0 step 6: training loss: 2163.596194413602\n",
      "Epoch 0 step 7: training loss: 2133.2250708445185\n",
      "Epoch 0 step 8: training loss: 2091.8494387986093\n",
      "Epoch 0 step 9: training loss: 2055.354698533398\n",
      "Epoch 0 step 10: training loss: 2022.4476218784084\n",
      "Epoch 0 step 11: training loss: 1984.676134950048\n",
      "Epoch 0 step 12: training loss: 1952.5090633861291\n",
      "Epoch 0 step 13: training loss: 1921.3099947644928\n",
      "Epoch 0 step 14: training loss: 1887.0773981716013\n",
      "Epoch 0 step 15: training loss: 1855.8236562399213\n",
      "Epoch 0 step 16: training loss: 1822.223850629015\n",
      "Epoch 0 step 17: training loss: 1796.237808185353\n",
      "Epoch 0 step 18: training loss: 1768.9351631880845\n",
      "Epoch 0 step 19: training loss: 1739.3041624248858\n",
      "Epoch 0 step 20: training loss: 1707.8207120172697\n",
      "Epoch 0 step 21: training loss: 1682.3712147464926\n",
      "Epoch 0 step 22: training loss: 1657.8482215092336\n",
      "Epoch 0 step 23: training loss: 1627.0207005967231\n",
      "Epoch 0 step 24: training loss: 1608.6251207954692\n",
      "Epoch 0 step 25: training loss: 1580.0211282073838\n",
      "Epoch 0 step 26: training loss: 1556.3560638923182\n",
      "Epoch 0 step 27: training loss: 1532.7251339242273\n",
      "Epoch 0 step 28: training loss: 1514.0704132216106\n",
      "Epoch 0 step 29: training loss: 1488.6260675613564\n",
      "Epoch 0 step 30: training loss: 1469.550771439894\n",
      "Epoch 0 step 31: training loss: 1449.0376130154664\n",
      "Epoch 0 step 32: training loss: 1427.8055006684378\n",
      "Epoch 0 step 33: training loss: 1409.2575934751799\n",
      "Epoch 0 step 34: training loss: 1390.9389347655604\n",
      "Epoch 0 step 35: training loss: 1374.4604524746023\n",
      "Epoch 0 step 36: training loss: 1352.950549282371\n",
      "Epoch 0 step 37: training loss: 1337.1339029846035\n",
      "Epoch 0 step 38: training loss: 1320.7006237448657\n",
      "Epoch 0 step 39: training loss: 1305.7150123315032\n",
      "Epoch 0 step 40: training loss: 1288.6662807639032\n",
      "Epoch 0 step 41: training loss: 1271.0336127280138\n",
      "Epoch 0 step 42: training loss: 1258.120700488561\n",
      "Epoch 0 step 43: training loss: 1244.843804047292\n",
      "Epoch 0 step 44: training loss: 1230.3369566532908\n",
      "Epoch 0 step 45: training loss: 1216.0781395213444\n",
      "Epoch 0 step 46: training loss: 1203.2672832394267\n",
      "Epoch 0 step 47: training loss: 1190.5695393622007\n",
      "Epoch 0 step 48: training loss: 1178.1644445319291\n",
      "Epoch 0 step 49: training loss: 1170.5290003857071\n",
      "Epoch 0 step 50: training loss: 1155.0053386778377\n",
      "Epoch 0 step 51: training loss: 1142.2194477943408\n",
      "Epoch 0 step 52: training loss: 1132.186222780372\n",
      "Epoch 0 step 53: training loss: 1121.2410224291032\n",
      "Epoch 0 step 54: training loss: 1109.536310680477\n",
      "Epoch 0 step 55: training loss: 1100.6648927418223\n",
      "Epoch 0 step 56: training loss: 1092.419104676767\n",
      "Epoch 0 step 57: training loss: 1083.142473278602\n",
      "Epoch 0 step 58: training loss: 1074.141697715312\n",
      "Epoch 0 step 59: training loss: 1068.0098646150532\n",
      "Epoch 0 step 60: training loss: 1058.2218427137395\n",
      "Epoch 0 step 61: training loss: 1048.289430786035\n",
      "Epoch 0 step 62: training loss: 1041.423204022613\n",
      "Epoch 0 step 63: training loss: 1033.473409999058\n",
      "Epoch 0 step 64: training loss: 1026.5941684281436\n",
      "Epoch 0 step 65: training loss: 1018.7296628773755\n",
      "Epoch 0 step 66: training loss: 1013.8876314779314\n",
      "Epoch 0 step 67: training loss: 1005.5420791043672\n",
      "Epoch 0 step 68: training loss: 1000.9582166457002\n",
      "Epoch 0 step 69: training loss: 992.5883945072574\n",
      "Epoch 0 step 70: training loss: 987.9917229846487\n",
      "Epoch 0 step 71: training loss: 982.4444890317951\n",
      "Epoch 0 step 72: training loss: 976.683124600178\n",
      "Epoch 0 step 73: training loss: 970.0588211318911\n",
      "Epoch 0 step 74: training loss: 965.2345114576249\n",
      "Epoch 0 step 75: training loss: 961.8640220404602\n",
      "Epoch 0 step 76: training loss: 955.746544490367\n",
      "Epoch 0 step 77: training loss: 951.6095337970369\n",
      "Epoch 0 step 78: training loss: 948.2154798844335\n",
      "Epoch 0 step 79: training loss: 942.7117926249139\n",
      "Epoch 0 step 80: training loss: 939.1046998014072\n",
      "Epoch 0 step 81: training loss: 420.09110756243666\n",
      "Epoch 0: train loss 1407.15341595693, train accuarcy 0.5067778825759888\n",
      "Epoch 0: valid loss 753.7707506295592, valid accuarcy 0.4740190804004669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.20s/it]\n"
     ]
    }
   ],
   "source": [
    "hrm_learner.fit(epoch=1, loss_callback=simple_loss_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train PRME FM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:40:08.307510Z",
     "start_time": "2019-09-12T05:40:08.291512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchPrmeFM()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prme_model = TorchPrmeFM(feature_dim=feat_dim, num_dim=NUM_DIM, init_mean=INIT_MEAN)\n",
    "prme_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:40:14.711044Z",
     "start_time": "2019-09-12T05:40:14.708053Z"
    }
   },
   "outputs": [],
   "source": [
    "adam_opt = optim.Adam(prme_model.parameters(), lr=LEARNING_RATE)\n",
    "schedular = optim.lr_scheduler.StepLR(adam_opt, step_size=1000, gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:43:19.936423Z",
     "start_time": "2019-09-12T05:43:17.555590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.fm_learner.FMLearner at 0x1dc898b43c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prme_learner = FMLearner(prme_model, adam_opt, schedular, movie_db)\n",
    "prme_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:44:01.531891Z",
     "start_time": "2019-09-12T05:43:40.427858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                  | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 0 step 0: training loss: 2409.502033348307\n",
      "Epoch 0 step 1: training loss: 2370.0208452277716\n",
      "Epoch 0 step 2: training loss: 2336.5124505587314\n",
      "Epoch 0 step 3: training loss: 2306.2763147460155\n",
      "Epoch 0 step 4: training loss: 2268.6344924120485\n",
      "Epoch 0 step 5: training loss: 2230.156575555031\n",
      "Epoch 0 step 6: training loss: 2198.702686673772\n",
      "Epoch 0 step 7: training loss: 2163.9317165013636\n",
      "Epoch 0 step 8: training loss: 2134.51797309998\n",
      "Epoch 0 step 9: training loss: 2105.8556911739424\n",
      "Epoch 0 step 10: training loss: 2070.495852674983\n",
      "Epoch 0 step 11: training loss: 2038.3732684976028\n",
      "Epoch 0 step 12: training loss: 2011.9124994403037\n",
      "Epoch 0 step 13: training loss: 1981.9813537128698\n",
      "Epoch 0 step 14: training loss: 1950.6311312519629\n",
      "Epoch 0 step 15: training loss: 1926.687022340544\n",
      "Epoch 0 step 16: training loss: 1897.9420741026152\n",
      "Epoch 0 step 17: training loss: 1871.4875323956776\n",
      "Epoch 0 step 18: training loss: 1846.559868280971\n",
      "Epoch 0 step 19: training loss: 1816.5440026091046\n",
      "Epoch 0 step 20: training loss: 1795.735894171025\n",
      "Epoch 0 step 21: training loss: 1770.4987863887818\n",
      "Epoch 0 step 22: training loss: 1746.699427165602\n",
      "Epoch 0 step 23: training loss: 1722.6204902950803\n",
      "Epoch 0 step 24: training loss: 1696.970068573409\n",
      "Epoch 0 step 25: training loss: 1674.3714226128357\n",
      "Epoch 0 step 26: training loss: 1653.5131272794304\n",
      "Epoch 0 step 27: training loss: 1635.871866151344\n",
      "Epoch 0 step 28: training loss: 1612.1356970000504\n",
      "Epoch 0 step 29: training loss: 1588.6368106162536\n",
      "Epoch 0 step 30: training loss: 1568.783929479399\n",
      "Epoch 0 step 31: training loss: 1549.576664770644\n",
      "Epoch 0 step 32: training loss: 1531.2221494330468\n",
      "Epoch 0 step 33: training loss: 1513.6795890125827\n",
      "Epoch 0 step 34: training loss: 1494.2790256391559\n",
      "Epoch 0 step 35: training loss: 1478.3298115343034\n",
      "Epoch 0 step 36: training loss: 1459.966600804463\n",
      "Epoch 0 step 37: training loss: 1444.778244524077\n",
      "Epoch 0 step 38: training loss: 1426.019035473321\n",
      "Epoch 0 step 39: training loss: 1407.834453352964\n",
      "Epoch 0 step 40: training loss: 1395.5924567078746\n",
      "Epoch 0 step 41: training loss: 1382.0411972106294\n",
      "Epoch 0 step 42: training loss: 1362.5009863090359\n",
      "Epoch 0 step 43: training loss: 1354.3377436426845\n",
      "Epoch 0 step 44: training loss: 1334.9203920668647\n",
      "Epoch 0 step 45: training loss: 1321.7083581950599\n",
      "Epoch 0 step 46: training loss: 1312.4756944804553\n",
      "Epoch 0 step 47: training loss: 1294.057245076665\n",
      "Epoch 0 step 48: training loss: 1280.5602994009407\n",
      "Epoch 0 step 49: training loss: 1273.8577059218214\n",
      "Epoch 0 step 50: training loss: 1259.8458172312714\n",
      "Epoch 0 step 51: training loss: 1251.263400022381\n",
      "Epoch 0 step 52: training loss: 1233.334939825198\n",
      "Epoch 0 step 53: training loss: 1224.5963718542976\n",
      "Epoch 0 step 54: training loss: 1215.9711304640496\n",
      "Epoch 0 step 55: training loss: 1203.894284225824\n",
      "Epoch 0 step 56: training loss: 1196.8967170848778\n",
      "Epoch 0 step 57: training loss: 1188.5235757175162\n",
      "Epoch 0 step 58: training loss: 1176.3951240398555\n",
      "Epoch 0 step 59: training loss: 1163.8360319540657\n",
      "Epoch 0 step 60: training loss: 1160.4850601446215\n",
      "Epoch 0 step 61: training loss: 1145.5863438783854\n",
      "Epoch 0 step 62: training loss: 1137.7119768938371\n",
      "Epoch 0 step 63: training loss: 1133.0425459041344\n",
      "Epoch 0 step 64: training loss: 1121.168572176534\n",
      "Epoch 0 step 65: training loss: 1115.4104716893833\n",
      "Epoch 0 step 66: training loss: 1102.6184518671457\n",
      "Epoch 0 step 67: training loss: 1098.8812466212446\n",
      "Epoch 0 step 68: training loss: 1091.5834388008657\n",
      "Epoch 0 step 69: training loss: 1088.6008737495304\n",
      "Epoch 0 step 70: training loss: 1082.0298750705736\n",
      "Epoch 0 step 71: training loss: 1068.3260686604438\n",
      "Epoch 0 step 72: training loss: 1063.6192877331912\n",
      "Epoch 0 step 73: training loss: 1060.1463224173226\n",
      "Epoch 0 step 74: training loss: 1055.3251996681868\n",
      "Epoch 0 step 75: training loss: 1048.0915015558749\n",
      "Epoch 0 step 76: training loss: 1039.173403633397\n",
      "Epoch 0 step 77: training loss: 1030.6741900914167\n",
      "Epoch 0 step 78: training loss: 1027.7094833012397\n",
      "Epoch 0 step 79: training loss: 1019.3133053268571\n",
      "Epoch 0 step 80: training loss: 1017.1540473222617\n",
      "Epoch 0 step 81: training loss: 495.33359684009156\n",
      "Epoch 0: train loss 1491.9127221177953, train accuarcy 0.5131440758705139\n",
      "Epoch 0: valid loss 835.3923763179478, valid accuarcy 0.44114527106285095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:21<00:00, 21.09s/it]\n"
     ]
    }
   ],
   "source": [
    "prme_learner.fit(epoch=1, loss_callback=simple_loss_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Trans FM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:44:51.938625Z",
     "start_time": "2019-09-12T05:44:51.909702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchTransFM()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_model = TorchTransFM(feature_dim=feat_dim, num_dim=NUM_DIM, init_mean=INIT_MEAN)\n",
    "trans_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:45:37.185482Z",
     "start_time": "2019-09-12T05:45:37.181493Z"
    }
   },
   "outputs": [],
   "source": [
    "adam_opt = optim.Adam(trans_model.parameters(), lr=LEARNING_RATE)\n",
    "schedular = optim.lr_scheduler.StepLR(adam_opt, step_size=1000, gamma=DECAY_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:45:59.920681Z",
     "start_time": "2019-09-12T05:45:59.900708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.fm_learner.FMLearner at 0x1dc8aff2c88>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_learner = FMLearner(trans_model, adam_opt, schedular, movie_db)\n",
    "trans_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:49:36.928718Z",
     "start_time": "2019-09-12T05:49:36.924729Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_loss_callback = partial(trans_loss, 1.0, 1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T05:50:05.886069Z",
     "start_time": "2019-09-12T05:49:44.013110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch 0 step 0: training loss: 2424.3826985573983\n",
      "Epoch 0 step 1: training loss: 2383.1879056801286\n",
      "Epoch 0 step 2: training loss: 2346.741142219497\n",
      "Epoch 0 step 3: training loss: 2303.000351476502\n",
      "Epoch 0 step 4: training loss: 2268.7321534445955\n",
      "Epoch 0 step 5: training loss: 2227.592242382835\n",
      "Epoch 0 step 6: training loss: 2200.833619191558\n",
      "Epoch 0 step 7: training loss: 2159.153435411897\n",
      "Epoch 0 step 8: training loss: 2125.1081323212557\n",
      "Epoch 0 step 9: training loss: 2085.8550067211927\n",
      "Epoch 0 step 10: training loss: 2055.5472285718806\n",
      "Epoch 0 step 11: training loss: 2022.4299097608082\n",
      "Epoch 0 step 12: training loss: 1982.9314823611498\n",
      "Epoch 0 step 13: training loss: 1962.753507330608\n",
      "Epoch 0 step 14: training loss: 1929.8476518772873\n",
      "Epoch 0 step 15: training loss: 1899.971883567648\n",
      "Epoch 0 step 16: training loss: 1862.300808161202\n",
      "Epoch 0 step 17: training loss: 1842.780249132087\n",
      "Epoch 0 step 18: training loss: 1815.5597437674578\n",
      "Epoch 0 step 19: training loss: 1784.1960122686278\n",
      "Epoch 0 step 20: training loss: 1765.615857749412\n",
      "Epoch 0 step 21: training loss: 1740.566118800406\n",
      "Epoch 0 step 22: training loss: 1705.4218721403208\n",
      "Epoch 0 step 23: training loss: 1691.5165289284807\n",
      "Epoch 0 step 24: training loss: 1655.5878939842842\n",
      "Epoch 0 step 25: training loss: 1638.239848040413\n",
      "Epoch 0 step 26: training loss: 1602.6494468508836\n",
      "Epoch 0 step 27: training loss: 1587.9011559748094\n",
      "Epoch 0 step 28: training loss: 1564.5224525762678\n",
      "Epoch 0 step 29: training loss: 1545.8850771351194\n",
      "Epoch 0 step 30: training loss: 1521.0940593903274\n",
      "Epoch 0 step 31: training loss: 1504.71467469377\n",
      "Epoch 0 step 32: training loss: 1479.8689788799531\n",
      "Epoch 0 step 33: training loss: 1465.0824995642827\n",
      "Epoch 0 step 34: training loss: 1445.0592935001537\n",
      "Epoch 0 step 35: training loss: 1424.4479444538931\n",
      "Epoch 0 step 36: training loss: 1409.7244917516891\n",
      "Epoch 0 step 37: training loss: 1388.4231055693072\n",
      "Epoch 0 step 38: training loss: 1375.515798574162\n",
      "Epoch 0 step 39: training loss: 1358.2873367355014\n",
      "Epoch 0 step 40: training loss: 1345.523124230418\n",
      "Epoch 0 step 41: training loss: 1331.7127462411336\n",
      "Epoch 0 step 42: training loss: 1313.597340646933\n",
      "Epoch 0 step 43: training loss: 1300.9006349508304\n",
      "Epoch 0 step 44: training loss: 1284.8095853348038\n",
      "Epoch 0 step 45: training loss: 1264.8909205824768\n",
      "Epoch 0 step 46: training loss: 1254.5188891531006\n",
      "Epoch 0 step 47: training loss: 1248.246961385939\n",
      "Epoch 0 step 48: training loss: 1223.7628096958701\n",
      "Epoch 0 step 49: training loss: 1215.4995407059246\n",
      "Epoch 0 step 50: training loss: 1208.8783842315256\n",
      "Epoch 0 step 51: training loss: 1197.0746250888599\n",
      "Epoch 0 step 52: training loss: 1176.0145401500351\n",
      "Epoch 0 step 53: training loss: 1172.6607300111739\n",
      "Epoch 0 step 54: training loss: 1163.0347450858526\n",
      "Epoch 0 step 55: training loss: 1150.5859031636273\n",
      "Epoch 0 step 56: training loss: 1150.355430050038\n",
      "Epoch 0 step 57: training loss: 1139.6370626108794\n",
      "Epoch 0 step 58: training loss: 1127.3481827258595\n",
      "Epoch 0 step 59: training loss: 1115.222508190806\n",
      "Epoch 0 step 60: training loss: 1112.372606080913\n",
      "Epoch 0 step 61: training loss: 1110.240858328925\n",
      "Epoch 0 step 62: training loss: 1094.0744222132494\n",
      "Epoch 0 step 63: training loss: 1083.4914140407332\n",
      "Epoch 0 step 64: training loss: 1076.061975532999\n",
      "Epoch 0 step 65: training loss: 1069.0187857900542\n",
      "Epoch 0 step 66: training loss: 1065.3960986569398\n",
      "Epoch 0 step 67: training loss: 1052.1775449373722\n",
      "Epoch 0 step 68: training loss: 1047.6212240673894\n",
      "Epoch 0 step 69: training loss: 1041.599353481261\n",
      "Epoch 0 step 70: training loss: 1035.3630868280554\n",
      "Epoch 0 step 71: training loss: 1022.3666375560401\n",
      "Epoch 0 step 72: training loss: 1023.9489584631424\n",
      "Epoch 0 step 73: training loss: 1012.2417157114271\n",
      "Epoch 0 step 74: training loss: 1004.9477811258341\n",
      "Epoch 0 step 75: training loss: 1013.7524431593035\n",
      "Epoch 0 step 76: training loss: 1003.4682899348292\n",
      "Epoch 0 step 77: training loss: 993.1778926508968\n",
      "Epoch 0 step 78: training loss: 986.3541813529185\n",
      "Epoch 0 step 79: training loss: 986.7190733278652\n",
      "Epoch 0 step 80: training loss: 979.0210389581418\n",
      "Epoch 0 step 81: training loss: 455.13459043572686\n",
      "Epoch 0: train loss 1453.7299297118193, train accuarcy 0.49536070227622986\n",
      "Epoch 0: valid loss 792.9498332346357, valid accuarcy 0.47613999247550964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:21<00:00, 21.86s/it]\n"
     ]
    }
   ],
   "source": [
    "trans_learner.fit(epoch=1, loss_callback=trans_loss_callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
