{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\python\\recommender\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import MovelenDataset, TorchMovielen10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Dataloader instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = T.device('cpu')\n",
    "BATCH = 32\n",
    "SHUFFLE = False\n",
    "WORKERS = 0\n",
    "FILE_PATH = Path(\"./inputs/ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-04 15:39:59,832 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in inputs\\ml-100k\\u.data\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0904 15:39:59.832129  8652 torch_movielen.py:41] Read dataset in inputs\\ml-100k\\u.data\n",
      "2019-09-04 15:39:59,843 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "I0904 15:39:59.843084  8652 torch_movielen.py:45] Original user size: 943\n",
      "2019-09-04 15:39:59,846 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "I0904 15:39:59.846060  8652 torch_movielen.py:46] Original item size: 1682\n",
      "2019-09-04 15:39:59,852 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "I0904 15:39:59.852046  8652 torch_movielen.py:52] Filter user size: 943\n",
      "2019-09-04 15:39:59,855 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "I0904 15:39:59.855036  8652 torch_movielen.py:53] Filter item size: 1413\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:8682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_movielen.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  train_df[cat_names] = data\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_movielen.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  valid_df[cat_names] = data\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_movielen.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  test_df[cat_names] = data\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "databunch = TorchMovielen10k(FILE_PATH, user_min=4, item_min=4)\n",
    "databunch.batch(BATCH)\n",
    "databunch.device(DEVICE)\n",
    "databunch.shuffle(SHUFFLE)\n",
    "databunch.workers(WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = databunch.get_dataloader(dataset_type='train')\n",
    "train_it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive batch shape: torch.Size([32, 3769])\n",
      "negtive batch shape: torch.Size([32, 3769])\n",
      "user index shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "user_index, pos_feats, neg_feats = train_it.next()\n",
    "print(\"positive batch shape:\", pos_feats.shape)\n",
    "print(\"negtive batch shape:\", neg_feats.shape)\n",
    "print(\"user index shape:\", user_index.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test each fm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = databunch.feat_dim\n",
    "num_dim = 32\n",
    "init_mean = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import TorchFM, TorchHrmFM, TorchPrmeFM, TorchTransFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test FM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchFM()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_model = TorchFM(feat_dim, num_dim, init_mean)\n",
    "fm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index, pos_feats, neg_feats = train_it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-6.3320e+00, -1.8593e+01, -1.8187e+00, -3.6522e+00, -8.7877e+00,\n",
       "         -1.4170e+01, -1.1217e+01,  3.2492e+01,  2.9107e+01, -1.5778e+00,\n",
       "          2.8179e+01,  3.1098e+01,  4.7941e+00,  5.3306e+01, -1.4949e+01,\n",
       "         -1.4957e+01,  8.3725e+01, -1.3907e+01, -1.0136e-02,  2.3218e+00,\n",
       "         -2.1499e+01,  2.8128e+01, -1.1814e+00, -1.0797e+01, -2.7615e+01,\n",
       "         -2.2710e+01,  1.6794e+01, -1.2926e+01,  2.9760e+01, -9.2205e+00,\n",
       "         -1.1150e+01,  9.9238e+00], dtype=torch.float64,\n",
       "        grad_fn=<SqueezeBackward0>),\n",
       " tensor([ 0.8997, -1.8188, -2.0658, -0.8265, -0.1294, -0.7602,  1.1092, -1.3965,\n",
       "         -1.7074, -1.1005,  0.2752, -0.4844, -1.2156, -0.9740, -1.0221, -0.4601,\n",
       "          0.7161, -1.1022, -0.6049, -0.6645, -1.3956,  0.6511, -0.6141,  0.7362,\n",
       "         -1.0170, -1.1702, -1.4416, -0.6788, -0.8981, -0.5981, -0.0235, -0.6781],\n",
       "        dtype=torch.float64, grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_model(pos_feats, neg_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test HRM FM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchHrmFM()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrm_model = TorchHrmFM(feat_dim, num_dim, init_mean)\n",
    "hrm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([33.1325, 31.2840, 33.8941, 37.8595, 24.3273, 33.6767, 33.3145, 24.9276,\n",
       "         34.0461, 46.3949, 26.7207, 33.6015, 39.6543, 33.0167, 32.8380, 29.0679,\n",
       "         32.3540, 32.9390, 37.6464, 36.5464, 27.9834, 36.6693, 29.5573, 32.4882,\n",
       "         28.0673, 37.9960, 34.6276, 35.7300, 31.4886, 30.7740, 47.2476, 31.6606],\n",
       "        dtype=torch.float64, grad_fn=<SqueezeBackward0>),\n",
       " tensor([37.1022, 32.9437, 27.1174, 30.4373, 29.8915, 27.6997, 33.6522, 30.2027,\n",
       "         39.7062, 32.9901, 25.4198, 26.7987, 32.7458, 33.6718, 40.8421, 37.2893,\n",
       "         31.7878, 35.4335, 33.6432, 31.2373, 23.8031, 40.4450, 29.9733, 37.3937,\n",
       "         29.8326, 36.5847, 38.0195, 36.8252, 38.0957, 37.6037, 37.5518, 32.3737],\n",
       "        dtype=torch.float64, grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrm_model(pos_feats, neg_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
       "                        14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
       "                        28, 29, 30, 31]]),\n",
       "       values=tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "                      3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "                      3., 3., 3., 3.]),\n",
       "       size=(32,), nnz=32, dtype=torch.float64, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = T.sparse.sum(pos_feats, dim=1)\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.to_dense().unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PRME FM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchPrmeFM()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prme_model = TorchPrmeFM(feat_dim, num_dim, init_mean)\n",
    "prme_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([60.9180, 57.1923, 66.3343, 57.8448, 62.4383, 72.0836, 81.6217, 82.6911,\n",
       "         67.9099, 69.5385, 63.9037, 59.3991, 58.1825, 63.3404, 61.0830, 58.7116,\n",
       "         58.1612, 68.8459, 54.9932, 47.4228, 62.0930, 74.1544, 62.9308, 67.1919,\n",
       "         66.9541, 65.5529, 54.0643, 62.9666, 57.2651, 66.6893, 57.8874, 67.4915],\n",
       "        dtype=torch.float64, grad_fn=<SqueezeBackward0>),\n",
       " tensor([50.1787, 67.8435, 52.7835, 63.8109, 57.6609, 63.2887, 72.7375, 69.3349,\n",
       "         73.9696, 63.7759, 52.7288, 67.4585, 61.2889, 73.3168, 61.4489, 55.8257,\n",
       "         63.0113, 73.0728, 50.5091, 52.7749, 69.9864, 62.3278, 68.4112, 72.7717,\n",
       "         45.5054, 60.6085, 60.6988, 64.1107, 67.2851, 60.9872, 54.5550, 64.5138],\n",
       "        dtype=torch.float64, grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prme_model(pos_feats, neg_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Trans FM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model = TorchTransFM(feat_dim, num_dim, init_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[47.9871, 47.7071, 49.3781,  ..., 47.7364, 49.1120, 48.0285],\n",
       "         [35.3914, 34.0698, 38.4322,  ..., 36.7168, 40.4203, 35.3162],\n",
       "         [16.7107, 20.9923, 20.5644,  ..., 19.8710, 19.7025, 18.7586],\n",
       "         ...,\n",
       "         [44.4349, 44.1552, 43.0757,  ..., 43.8500, 45.3918, 46.0052],\n",
       "         [38.0985, 35.4504, 36.1466,  ..., 38.6471, 38.6220, 35.9761],\n",
       "         [40.7495, 37.8852, 37.1862,  ..., 38.5450, 41.7622, 39.7110]],\n",
       "        dtype=torch.float64, grad_fn=<SqueezeBackward0>),\n",
       " tensor([ 92.4897,  95.9412,  71.5015,  83.8820,  94.2005, 110.1614,  88.4120,\n",
       "          93.7598,  91.5013,  60.8054,  96.1686,  76.6246,  90.0194,  80.8533,\n",
       "          79.8691,  88.4803, 108.2334, 110.7207, 107.8850, 101.6066,  76.7894,\n",
       "         117.2790,  88.6113,  90.1018,  90.3195,  64.6207, 109.3250,  85.4523,\n",
       "          76.7103,  90.7464,  85.9680,  82.5757], dtype=torch.float64,\n",
       "        grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_model(pos_feats, neg_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find size error!!\n",
    "\n",
    "#### Test trans model forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = trans_model._feature_dim\n",
    "param_linear = trans_model.param_linear\n",
    "param_emb = trans_model.param_emb\n",
    "param_trans = trans_model.param_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "pos_linear = T.mm(pos_feats, param_linear)\n",
    "neg_linear = T.mm(neg_feats, param_linear)\n",
    "print(pos_linear.shape)\n",
    "print(neg_linear.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3769, 1])\n",
      "torch.Size([3769, 1])\n",
      "torch.Size([3769, 1])\n",
      "torch.Size([3769, 1])\n"
     ]
    }
   ],
   "source": [
    "var_sum_op = T.ones(feature_dim, 1, dtype=T.double)\n",
    "var_emb_product = T.sum(T.pow(param_emb, 2), dim=1, keepdim=True)\n",
    "var_trans_product = T.sum(T.pow(param_trans, 2), dim=1, keepdim=True)\n",
    "var_emb_trans_product = T.sum(param_emb * param_trans,\n",
    "                              dim=1,\n",
    "                              keepdim=True)\n",
    "print(var_sum_op.shape)\n",
    "print(var_emb_product.shape)\n",
    "print(var_trans_product.shape)\n",
    "print(var_emb_trans_product.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common term positive\n",
    "pos_feats_sum = T.mm(pos_feats, var_sum_op)\n",
    "pos_emb_mul = T.mm(pos_feats, param_emb)\n",
    "pos_trans_mul = T.mm(pos_feats, param_trans)\n",
    "\n",
    "# Common terms negative\n",
    "neg_feats_sum = T.mm(neg_feats, var_sum_op)\n",
    "neg_emb_mul = T.mm(neg_feats, param_emb)\n",
    "neg_trans_mul = T.mm(neg_feats, param_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n",
      "---------------------------\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(pos_feats_sum.shape)\n",
    "print(pos_emb_mul.shape)\n",
    "print(pos_trans_mul.shape)\n",
    "print(\"---------------------------\")\n",
    "print(neg_feats_sum.shape)\n",
    "print(neg_emb_mul.shape)\n",
    "print(neg_trans_mul.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term 1 pos\n",
    "prod_term_pos = T.mm(pos_feats, var_emb_product)\n",
    "term_1_pos = prod_term_pos * pos_feats_sum\n",
    "\n",
    "# Term 1 neg\n",
    "prod_term_neg = T.mm(neg_feats, var_emb_product)\n",
    "term_1_neg = prod_term_neg * neg_feats_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "-----------------------\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(prod_term_pos.shape)\n",
    "print(term_1_pos.shape)\n",
    "print(\"-----------------------\")\n",
    "print(prod_term_neg.shape)\n",
    "print(term_1_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term 2 pos\n",
    "prod_term_pos = T.mm(pos_feats, param_trans)\n",
    "term_2_pos = prod_term_pos * pos_feats_sum\n",
    "\n",
    "# Term 2 neg\n",
    "prod_term_neg = T.mm(neg_feats, var_trans_product)\n",
    "term_2_neg = prod_term_neg * pos_feats_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(term_2_pos.shape)\n",
    "print(term_2_neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find error !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 93.3357,  87.8569,  76.6370,  86.5213,  80.0202, 133.7127,  94.9688,\n",
       "          89.1366,  91.9335,  82.4871,  91.7615,  89.6770,  92.2411,  77.6657,\n",
       "          87.7062,  98.8069,  94.2637, 108.8042,  98.6036, 101.5182,  97.6163,\n",
       "          86.7221,  84.8828,  82.1383,  97.0879,  90.8993, 110.1206,  80.5946,\n",
       "          98.5954,  94.4523,  84.5089,  94.7278], dtype=torch.float64,\n",
       "        grad_fn=<SqueezeBackward0>),\n",
       " tensor([ 92.4897,  95.9412,  71.5015,  83.8820,  94.2005, 110.1614,  88.4120,\n",
       "          93.7598,  91.5013,  60.8054,  96.1686,  76.6246,  90.0194,  80.8533,\n",
       "          79.8691,  88.4803, 108.2334, 110.7207, 107.8850, 101.6066,  76.7894,\n",
       "         117.2790,  88.6113,  90.1018,  90.3195,  64.6207, 109.3250,  85.4523,\n",
       "          76.7103,  90.7464,  85.9680,  82.5757], dtype=torch.float64,\n",
       "        grad_fn=<SqueezeBackward0>))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_model(pos_feats, neg_feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
