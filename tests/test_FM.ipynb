{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:11:20.369098Z",
     "start_time": "2019-07-16T03:11:20.126767Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:11:21.143757Z",
     "start_time": "2019-07-16T03:11:20.894236Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:11:22.038834Z",
     "start_time": "2019-07-16T03:11:21.997918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\python\\recommender\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:14:22.422470Z",
     "start_time": "2019-07-16T03:14:22.301965Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets.torch_movielen import TorchMovielen10k\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:15:03.577858Z",
     "start_time": "2019-07-16T03:15:02.717981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-16 11:15:02,838 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-07-16 11:15:02,838 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-07-16 11:15:02,838 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-07-16 11:15:02,838 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-07-16 11:15:02,838 - C:\\Projects\\python\\recommender\\utils.py - INFO - Read dataset in ./inputs/ml-100k/u.data\n",
      "I0716 11:15:02.838742 12240 torch_movielen.py:45] Read dataset in ./inputs/ml-100k/u.data\n",
      "2019-07-16 11:15:02,856 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "2019-07-16 11:15:02,856 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "2019-07-16 11:15:02,856 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "2019-07-16 11:15:02,856 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "2019-07-16 11:15:02,856 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original user size: 943\n",
      "I0716 11:15:02.856930 12240 torch_movielen.py:49] Original user size: 943\n",
      "2019-07-16 11:15:02,864 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "2019-07-16 11:15:02,864 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "2019-07-16 11:15:02,864 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "2019-07-16 11:15:02,864 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "2019-07-16 11:15:02,864 - C:\\Projects\\python\\recommender\\utils.py - INFO - Original item size: 1682\n",
      "I0716 11:15:02.864905 12240 torch_movielen.py:50] Original item size: 1682\n",
      "2019-07-16 11:15:02,874 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "2019-07-16 11:15:02,874 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "2019-07-16 11:15:02,874 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "2019-07-16 11:15:02,874 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "2019-07-16 11:15:02,874 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter user size: 943\n",
      "I0716 11:15:02.874954 12240 torch_movielen.py:56] Filter user size: 943\n",
      "2019-07-16 11:15:02,883 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "2019-07-16 11:15:02,883 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "2019-07-16 11:15:02,883 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "2019-07-16 11:15:02,883 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "2019-07-16 11:15:02,883 - C:\\Projects\\python\\recommender\\utils.py - INFO - Filter item size: 1413\n",
      "I0716 11:15:02.883852 12240 torch_movielen.py:57] Filter item size: 1413\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:8682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_movielen.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  train_df[cat_names] = data\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_movielen.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  valid_df[cat_names] = data\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n",
      "C:\\Projects\\python\\recommender\\datasets\\torch_movielen.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  test_df[cat_names] = data\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3395: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "c:\\projects\\python\\recommender\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3367: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "databunch = TorchMovielen10k('./inputs/ml-100k/u.data', user_min=4, item_min=4)\n",
    "databunch.batch(16)\n",
    "databunch.device(T.device('cpu'))\n",
    "databunch.shuffle(False)\n",
    "databunch.workers(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:15:29.630536Z",
     "start_time": "2019-07-16T03:15:29.509715Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = databunch.get_dataloader(dataset_type='train')\n",
    "valid_dl = databunch.get_dataloader(dataset_type='valid')\n",
    "test_dl = databunch.get_dataloader(dataset_type='test')\n",
    "train_it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:15:45.893661Z",
     "start_time": "2019-07-16T03:15:45.749865Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_batch, neg_batch = train_it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:15:47.045145Z",
     "start_time": "2019-07-16T03:15:46.941820Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:15:47.697353Z",
     "start_time": "2019-07-16T03:15:47.597761Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_dict = movielen.cat_dict\n",
    "pos_names = movielen.pos_cat_names\n",
    "neg_names = movielen.neg_cat_names\n",
    "num_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:17:17.357790Z",
     "start_time": "2019-07-16T03:17:17.253594Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.torch_fm import TorchFM, FMLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:21:29.128942Z",
     "start_time": "2019-07-16T03:21:29.022055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchFM(\n",
       "  (emb_linear_layer): ModuleList(\n",
       "    (0): Embedding(943, 1)\n",
       "    (1): Embedding(1413, 1)\n",
       "    (2): Embedding(1415, 1)\n",
       "  )\n",
       "  (emb_factor_layer): ModuleList(\n",
       "    (0): Embedding(943, 10)\n",
       "    (1): Embedding(1413, 10)\n",
       "    (2): Embedding(1415, 10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TorchFM(cat_dict, pos_names, neg_names, num_dim=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:22:24.495737Z",
     "start_time": "2019-07-16T03:22:24.346571Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_preds, neg_preds = model(pos_batch, neg_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:22:40.955347Z",
     "start_time": "2019-07-16T03:22:40.829490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -2.3542, -15.5298,  23.6379,  -2.5658, -19.6251, -12.7302,   2.4559,\n",
      "         -1.4607,   5.8175, -11.1045,  -2.1898,  -6.4191,  11.1794,   2.9016,\n",
      "         -1.5356,  -4.3187], grad_fn=<SqueezeBackward0>)\n",
      "tensor([-20.2431, -13.3625,  -7.2352,  -8.0666, -10.4701,  -5.1879,  -0.4698,\n",
      "         -8.5503,  -0.9939,  -2.7569,  -8.5696,  -2.4610, -10.3936,  12.5140,\n",
      "        -19.3883,  -7.7941], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pos_preds)\n",
    "print(neg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:23:10.167849Z",
     "start_time": "2019-07-16T03:23:10.069491Z"
    }
   },
   "outputs": [],
   "source": [
    "learner = FMLearner(model, databunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:23:44.065798Z",
     "start_time": "2019-07-16T03:23:43.957340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([44.6341], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bprloss = learner.criterion(pos_preds, neg_preds, linear_reg=0.001)\n",
    "bprloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:27:54.668751Z",
     "start_time": "2019-07-16T03:27:54.557084Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_ranks = (pos_preds - neg_preds) > 0\n",
    "binary_ranks = binary_ranks.to(T.float)\n",
    "users_index = pos_batch[:, 0]\n",
    "users, user_counts = T.unique(users_index, return_counts=True)\n",
    "user_counts = user_counts.to(T.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:29:11.714612Z",
     "start_time": "2019-07-16T03:29:11.612687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user index:  tensor([850, 850, 850, 850, 850, 850, 850, 850, 850, 850, 711, 711, 711, 711,\n",
      "        711, 711])\n",
      "user counts:  tensor([ 6., 10.])\n"
     ]
    }
   ],
   "source": [
    "print(\"user index: \", users_index)\n",
    "print(\"user counts: \", user_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T03:29:34.536532Z",
     "start_time": "2019-07-16T03:29:34.436817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.user_counts.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T04:15:59.383512Z",
     "start_time": "2019-07-16T04:15:59.273734Z"
    }
   },
   "outputs": [],
   "source": [
    "learner.user_counts[users] += user_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T04:16:00.802909Z",
     "start_time": "2019-07-16T04:16:00.705569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 20.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.user_counts[users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:03:07.534813Z",
     "start_time": "2019-07-15T09:03:07.366488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.metric(pos_batch, pos_preds, neg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:29.434148Z",
     "start_time": "2019-07-15T09:11:29.277537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_ranks = (pos_preds - neg_preds) > 0\n",
    "binary_ranks = binary_ranks.to(T.float)\n",
    "binary_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:32.830771Z",
     "start_time": "2019-07-15T09:11:32.685126Z"
    }
   },
   "outputs": [],
   "source": [
    "users_index = pos_batch[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:33.434913Z",
     "start_time": "2019-07-15T09:11:33.293542Z"
    }
   },
   "outputs": [],
   "source": [
    "users, user_counts = T.unique(users_index, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:34.187568Z",
     "start_time": "2019-07-15T09:11:34.038361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: tensor([ 32,  48,  56, 233, 307, 392, 425, 436, 510, 534, 628, 675, 701, 822,\n",
      "        891, 932])\n",
      "user counts: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"users: {}\".format(users))\n",
    "print(\"user counts: {}\".format(user_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:37.039760Z",
     "start_time": "2019-07-15T09:11:36.893128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([675, 932,  48, 307, 628, 436, 701, 510, 233, 891, 392, 425,  56, 534,\n",
       "         32, 822])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:38.180794Z",
     "start_time": "2019-07-15T09:11:38.038178Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:40.113976Z",
     "start_time": "2019-07-15T09:11:39.965466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_per_user = scatter_mean(binary_ranks, users_index)\n",
    "auc_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T09:11:43.598770Z",
     "start_time": "2019-07-15T09:11:43.445152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6875)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.sum(auc_per_user) / users.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "recommender"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
